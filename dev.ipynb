{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from cot.run import debug_parse_option\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from cot.dataset import CoTDataset\n",
    "from cot.learner import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = debug_parse_option(notebook=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_id, cache_dir=args.hf_cache_dir)\n",
    "# model = AutoModelForCausalLM.from_pretrained(args.model_id, cache_dir=args.hf_cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nli task!\n",
      "\n",
      "\n",
      "Ablation 1 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=1015, preprocessed_dir='datadump/preprocessed', dataset_name='presuppositions_as_nli', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='presuppositions_as_nli', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=0, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e3cb4d15b4af1a66b4843de9980e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-3469f907dcb2dada.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5767d5db5f3e8e3d.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ed7528e33f9afaf.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-460a42fcdacbf8e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Sentence 1:  Thirty-three students died before the storm moved on. the winds finally dissipated at 4:30 P.M. After ripping up half of Princeton, the winds finally dissipated at 4:30 P.M. \n",
      "Sentence 2: The students ripped up half of Princeton.\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['contradiction']\n",
      "\n",
      "\n",
      "Ablation 2 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=1015, preprocessed_dir='datadump/preprocessed', dataset_name='presuppositions_as_nli', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='presuppositions_as_nli', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=0, rebuild_cache=True, shuffle_cots=False, step_by_step=True, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a068bd6115a4118a77b3f7cf9261973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-3469f907dcb2dada.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5767d5db5f3e8e3d.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ed7528e33f9afaf.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-460a42fcdacbf8e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Sentence 1:  Thirty-three students died before the storm moved on. the winds finally dissipated at 4:30 P.M. After ripping up half of Princeton, the winds finally dissipated at 4:30 P.M. \n",
      "Sentence 2: The students ripped up half of Princeton.\n",
      "Let's think step by step.\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['contradiction']\n",
      "\n",
      "\n",
      "Ablation 3 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=1015, preprocessed_dir='datadump/preprocessed', dataset_name='presuppositions_as_nli', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='presuppositions_as_nli', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=1, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=True, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74482a8fa3f4e50be78ebdcacc39411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-3469f907dcb2dada.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5767d5db5f3e8e3d.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ed7528e33f9afaf.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-460a42fcdacbf8e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Sentence 1:In 1975, Peacock didn't begin filming grizzly bears, hoping it would help him plead the bears' case. \n",
      "Sentence 2: Peacock didn't train grizzly bears before 1975.\n",
      "A:neutral\n",
      "Sentence 1:  Thirty-three students died before the storm moved on. the winds finally dissipated at 4:30 P.M. After ripping up half of Princeton, the winds finally dissipated at 4:30 P.M. \n",
      "Sentence 2: The students ripped up half of Princeton.\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['contradiction']\n",
      "\n",
      "\n",
      "Ablation 4 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=1015, preprocessed_dir='datadump/preprocessed', dataset_name='presuppositions_as_nli', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='presuppositions_as_nli', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=1, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056355fac90144fb9411b3bd60a8e79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-3469f907dcb2dada.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5767d5db5f3e8e3d.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ed7528e33f9afaf.arrow\n",
      "Loading cached processed dataset at /home/lcur1112/.cache/huggingface/datasets/json/default-ba76fde3db5b84f4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-460a42fcdacbf8e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Sentence 1:In 1975, Peacock didn't begin filming grizzly bears, hoping it would help him plead the bears' case. \n",
      "Sentence 2: Peacock didn't train grizzly bears before 1975.\n",
      "Explanation:It's possible that Peacock had been training grizzly bears previously even without filming them; so the relationship is neutral, sentence 1 neither entails nor contradicts sentence 2.\n",
      "A:neutral\n",
      "Sentence 1:  Thirty-three students died before the storm moved on. the winds finally dissipated at 4:30 P.M. After ripping up half of Princeton, the winds finally dissipated at 4:30 P.M. \n",
      "Sentence 2: The students ripped up half of Princeton.\n",
      "Explanation:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['contradiction']\n",
      "arithmetic task!\n",
      "\n",
      "\n",
      "Ablation 1 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=512, preprocessed_dir='datadump/preprocessed', dataset_name='arithmetic', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='arithmetic_3_digit_division', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=0, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bigbench (/home/lcur1112/CoT/datadump/hf/tasksource___bigbench/arithmetic/1.0.0/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Q: What is 972 divided by 36?\n",
      "  choice: 27\n",
      "  choice: 43\n",
      "  choice: banana\n",
      "  choice: 4817\n",
      "  choice: 86\n",
      "  choice: 7\n",
      "  choice: house\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['27']\n",
      "\n",
      "\n",
      "Ablation 2 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=512, preprocessed_dir='datadump/preprocessed', dataset_name='arithmetic', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='arithmetic_3_digit_division', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=0, rebuild_cache=True, shuffle_cots=False, step_by_step=True, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bigbench (/home/lcur1112/CoT/datadump/hf/tasksource___bigbench/arithmetic/1.0.0/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Q: What is 972 divided by 36?\n",
      "  choice: 27\n",
      "  choice: 43\n",
      "  choice: banana\n",
      "  choice: 4817\n",
      "  choice: 86\n",
      "  choice: 7\n",
      "  choice: house\n",
      "Let's think step by step.\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['27']\n",
      "\n",
      "\n",
      "Ablation 3 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=512, preprocessed_dir='datadump/preprocessed', dataset_name='arithmetic', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='arithmetic_3_digit_division', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=1, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=True, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bigbench (/home/lcur1112/CoT/datadump/hf/tasksource___bigbench/arithmetic/1.0.0/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Q:What is 842 divided by 1?\n",
      "  choice: 456\n",
      "  choice: 842\n",
      "  choice: house\n",
      "  choice: 14513\n",
      "  choice: 1\n",
      "  choice: banana\n",
      "  choice: 820\n",
      "A:842\n",
      "Q: What is 972 divided by 36?\n",
      "  choice: 27\n",
      "  choice: 43\n",
      "  choice: banana\n",
      "  choice: 4817\n",
      "  choice: 86\n",
      "  choice: 7\n",
      "  choice: house\n",
      "A:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['27']\n",
      "\n",
      "\n",
      "Ablation 4 !\n",
      "Namespace(train=True, wandb_run=None, model_id='bigscience/bloom-1b1', hf_cache_dir='datadump/hf', debug=True, model_max_length=512, preprocessed_dir='datadump/preprocessed', dataset_name='arithmetic', dataset_is_bigbench=True, arithmetic_task_name='3_digit_division', bigbench_explanations_dataset='arithmetic_3_digit_division', bigbench_explanations_type='handtuned', bigbench_explanations_path='data/bigbench-explanations/', n_shot=1, rebuild_cache=True, shuffle_cots=False, step_by_step=False, no_explanation=False, qae=False, lr=0.001, max_epochs=1, batch_size=8, seed=666, lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_bias='none')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bigbench (/home/lcur1112/CoT/datadump/hf/tasksource___bigbench/arithmetic/1.0.0/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a subset of the dataset\n",
      "\n",
      "## untokenized_sample ##\n",
      "\n",
      "Q:What is 842 divided by 1?\n",
      "  choice: 456\n",
      "  choice: 842\n",
      "  choice: house\n",
      "  choice: 14513\n",
      "  choice: 1\n",
      "  choice: banana\n",
      "  choice: 820\n",
      "Explanation:Dividing any number by 1 does not change it, so 842 / 1 = 842.\n",
      "A:842\n",
      "Q: What is 972 divided by 36?\n",
      "  choice: 27\n",
      "  choice: 43\n",
      "  choice: banana\n",
      "  choice: 4817\n",
      "  choice: 86\n",
      "  choice: 7\n",
      "  choice: house\n",
      "Explanation:\n",
      "\n",
      "## labels_untokenized ##\n",
      "\n",
      "['27']\n"
     ]
    }
   ],
   "source": [
    "tasks = ['nli', 'arithmetic']\n",
    "\n",
    "for task in tasks:\n",
    "# for task in tasks[1:]:\n",
    "# for task in tasks[:1]:\n",
    "    \n",
    "    print(f'{task} task!')\n",
    "\n",
    "    args = debug_parse_option(notebook=True)\n",
    "\n",
    "    if task == 'arithmetic':\n",
    "        args.dataset_name='arithmetic'\n",
    "        args.arithmetic_task_name='3_digit_division'\n",
    "        args.bigbench_explanations_dataset='arithmetic_3_digit_division'\n",
    "        args.dataset_is_bigbench=True\n",
    "    elif task == 'nli':\n",
    "        args.dataset_name='presuppositions_as_nli'\n",
    "        args.bigbench_explanations_dataset='presuppositions_as_nli'\n",
    "        args.dataset_is_bigbench=True\n",
    "        args.model_max_length=1015\n",
    "    else:\n",
    "        raise ValueError(f'Unknown task {task}')\n",
    "\n",
    "\n",
    "    ablations = {\n",
    "        1 : {'n_shot' : 0, 'step_by_step' : False, 'no_explanation' : False},\n",
    "        2 : {'n_shot' : 0, 'step_by_step' : True,  'no_explanation' : False},\n",
    "        3 : {'n_shot' : 1, 'step_by_step' : False, 'no_explanation' : True},\n",
    "        4 : {'n_shot' : 1, 'step_by_step' : False, 'no_explanation' : False},\n",
    "    }\n",
    "\n",
    "    for k, args_dict in ablations.items():\n",
    "        print(f'\\n\\nAblation {k} !')\n",
    "        args.n_shot, args.step_by_step, args.no_explanation = args_dict.values()\n",
    "\n",
    "        print(args)\n",
    "\n",
    "        x = CoTDataset(args, tokenizer, 'train')[0]\n",
    "        print('\\n## untokenized_sample ##\\n')\n",
    "        print(x['untokenized_sample'])\n",
    "\n",
    "        print('\\n## labels_untokenized ##\\n')\n",
    "        print(x['labels_untokenized'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
